 
<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Capstone Schedule</title>
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta property="og:title" content="C Server">
        <meta property="og:author" content="Michael Anderson">
        <link rel="stylesheet" href="res/css/bootstrap.min.css">
        <link rel="stylesheet" href="res/css/main.css">
        <script src="res/js/jquery.min.js"></script>
        <script src="res/js/bootstrap.min.js"></script>
    </head>
    <body>

      <h2 id='capTitle'>Explainable Text Clustering</h2>
      <br>
      <div id="clustdesc" class="mlacontainer">
          <b class="clusttitle">Task:</b><br>
          <p class="clustpar">
            Create a tool that, given a body of unstructured text documents and a user prompt, first clusters the documents based on their semantic relationship to the prompt, then generates descriptive labels for each cluster. For example, the prompt "positive phone reviews" might return Amazon reviews clustered on "battery life," "connection," "camera." A successful tool will filter the documents, group them, and provide meaningful explanations. This will require knowledge of text embeddings, clustering algorithms, text generation, and semantic relevancy tests.
          </p>
          <p class="clustpar">
            Because a particular similarity metric does not entail predictability or semantic usefulness, a successful tool must learn semantically useful features to cluster on. The defining metric for this tool's success will be how well labels can be used to locate clusters - that is, how accurately we can remake a cluster by performing a relevancy search over the body of texts using that cluster's label. A tool that describes accurately should also filter well, since the two operations are effectively the inverses of each other.
          </p>
          <b class="clusttitle">Specifications:</b><br>
          <p class="clustpar">
            <ol>
                <li>This tool should return only relevant documents</li> 
                <li>Clusters should have semantically meaning relationships, i.e. not on the basis that all documents in a cluster used the word "should" with the same frequency</li>
                <li>Clusters do not need to be flat. Heirarchical clustering is OK.</li>
                <li>Work will be done on common open source, labelled data sets</li>
                <li>Code reuse is OK, provided it is properly attributed</li>
            </ol>
          </p>
      </div>
      <div id='scheddivline'></div>
      <h3 id='capSubTitle'>LMI Capstone Schedule</h3>

      <div class="mlacontainer">
        <div class='item'>
          <div class="datetitle"><b>Sept. 16th – Sept. 20th</b></div>
          Readings<br>
          <ul>
            <li><a href="http://spark-public.s3.amazonaws.com/nlp/slides/intro.pdf">Introduction to NLP</a></li>
            <li><a href="http://spark-public.s3.amazonaws.com/nlp/slides/naivebayes.pdf">Bag of Words Model (slides 1-19)</a></li>
          </ul>

          Python<br>
          <ul>
            <li><a href=https://www.learnpython.org/en/Classes_and_Objects>Python - Classes</a></li>
          </ul>
        </div>

        <div class='item'>
           <div class="datetitle"><b>Sept. 23rd – Sept. 27th</b></div>
          Readings<br>
          <ul>
            <li><a href="https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf">Introduction to Custering, K-Means (slides 1-24)</a></li>
            <li><a href="http://www.tfidf.com"> TF-IDF Weighting</a></li>
          </ul>

          Python<br>
          <ul>
            <li><a href=https://www.learnpython.org/en/Functions>Python - Functions</a></li>
          </ul>
        </div>

        <div class='item'>
           <div class="datetitle"><b>Sept. 30th – Oct. 4th</b></div>
          Readings<br>
          <ul>
            <li><a href="https://explosion.ai/blog/deep-learning-formula-nlp">NLP and Deep Learning</a></li>
            <li><a href="https://medium.com/@b.terryjack/nlp-everything-about-word-embeddings-9ea21f51ccfe">Word Embeddings (Read sections on one-hot, feature vectors, and neural embeddings)</a></li>
          </ul>
          Self-Research (1 article, paper, or technique)<br>
          <ul>
            <li>3 Minute Presentations</li>
          </ul>
        </div>

        <div class='item'>
           <div class="datetitle"><b>Oct. 7th – Oct. 11th</b></div>
          Readings<br>
          <ul>
            <li>TBD</li>
          </ul>
          Self-Research (1 article, paper, or technique)<br>
          <ul>
            <li>3 Minute Presentations</li>
          </ul>
        </div>

        <div class='item'>
           <div class="datetitle"><b>Oct. 14th – Oct. 18th</b></div>
          Readings<br>
          <ul>
            <li>TBD</li>
          </ul>
           Self-Research (1 article, paper, or technique)<br>
          <ul>
            <li>3 Minute Presentations</li>
          </ul>
        </div>

        <div class='item'>
           <div class="datetitle"><b>Oct. 21st – Oct. 25th</b></div>
          Readings<br>
          <ul>
            <li>TBD</li>
          </ul>
          Self-Research (1 article, paper, or technique)<br>
          <ul>
            <li>3 Minute Presentations</li>
          </ul>
        </div>
      </div>
  
        <footer>
            <div class="container">
                <div class="col-sm-10" id="m_footer">
                    <hr>
                    © Michael Anderson 2019 - Powered by <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>
                </div>
            </div>
        </footer>

    </body>
</html>
